{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnAxx8vEcJ+RzFjuz0dBdH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AinzOwl/mysticai-colab/blob/main/MusicGen_Mystic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHgEc7edARHo"
      },
      "outputs": [],
      "source": [
        "!pip install pipeline-ai torch audiocraft torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Using small model, better results would be obtained with `medium` or `large`.\n",
        "model = MusicGen.get_pretrained('melody')\n",
        "segment_duration = 30\n",
        "model.set_generation_params(\n",
        "    use_sampling=True,\n",
        "    top_k=250,\n",
        "    duration=segment_duration\n",
        ")\n",
        "\n",
        "total_duration = 40\n",
        "overlap = 5\n",
        "\n",
        "desc = ['80s pop track with bassy drums and synth']\n",
        "\n",
        "segment = model.generate(descriptions=desc, progress=True)\n",
        "total_duration -= segment_duration\n",
        "while total_duration > 0:\n",
        "    last_sec = segment[:, :, -overlap*model.sample_rate:]\n",
        "    next_segment = model.generate_continuation(last_sec, model.sample_rate, descriptions=desc, progress=True)\n",
        "    segment = torch.cat([segment[:, :, :-overlap*model.sample_rate], next_segment], 2)\n",
        "    total_duration -= segment_duration - overlap\n",
        "    if total_duration < segment_duration:\n",
        "        segment_duration = total_duration + overlap\n",
        "        model.set_generation_params(\n",
        "            use_sampling=True,\n",
        "            top_k=250,\n",
        "            duration=segment_duration\n",
        "        )\n",
        "\n",
        "output = segment.detach().cpu().float()[0]\n",
        "with NamedTemporaryFile(\"wb\", suffix=\".wav\", delete=False) as file:\n",
        "    audio_write(\n",
        "        file.name, output, model.sample_rate, strategy=\"loudness\",\n",
        "        loudness_headroom_db=16, loudness_compressor=True, add_suffix=False)\n",
        "    print(f'Saved to {file.name}')"
      ],
      "metadata": {
        "id": "xMNS9Zh5KfCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = input(\"Enter your mystic.ai API key: \")\n",
        "!pipeline cluster login catalystapi {key} -u https://www.mystic.ai -a"
      ],
      "metadata": {
        "id": "8h2bRTgGAptI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import subprocess\n",
        "\n",
        "from audiocraft.models import MusicGen\n",
        "from audiocraft.data.audio import audio_write\n",
        "from audiocraft.utils.notebook import display_audio\n",
        "from tempfile import NamedTemporaryFile\n",
        "\n",
        "from pipeline import Pipeline, Variable, entity, pipe\n",
        "from pipeline.cloud import compute_requirements, environments, pipelines\n",
        "from pipeline.objects import File\n"
      ],
      "metadata": {
        "id": "ecgeMzF5AupZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@entity\n",
        "class MusicgenModel:\n",
        "    def __init__(self):\n",
        "        ...\n",
        "\n",
        "    @pipe(on_startup=True, run_once=True)\n",
        "    def load(self):\n",
        "        import torchaudio\n",
        "        from audiocraft.models import MusicGen\n",
        "        self.model = MusicGen.get_pretrained('facebook/musicgen-melody')\n",
        "\n",
        "\n",
        "    @pipe\n",
        "    def predict(self, prompt: str, duration: int, samples: int, melodySample: File) -> File:\n",
        "        from audiocraft.data.audio import audio_write\n",
        "\n",
        "        segment_duration = 30\n",
        "        self.model.set_generation_params(\n",
        "            use_sampling=True,\n",
        "            top_k=250,\n",
        "            duration=segment_duration\n",
        "        )\n",
        "\n",
        "        total_duration = duration\n",
        "        if (total_duration > 30):\n",
        "          genduration = 30\n",
        "        else:\n",
        "          genduration = total_duration\n",
        "        overlap = 5\n",
        "\n",
        "        self.model.set_generation_params(duration=genduration)\n",
        "        wav = self.model.generate_unconditional(samples)\n",
        "        descriptions = prompt\n",
        "        wav = self.model.generate(descriptions)\n",
        "\n",
        "        melody, sr = torchaudio.load(str(melodySample.path), format=\"wav\")\n",
        "        segment = self.model.generate_with_chroma(descriptions, melody[None].expand(genduration, -1, -1), sr)\n",
        "\n",
        "        total_duration -= segment_duration\n",
        "        while total_duration > 0:\n",
        "            last_sec = segment[:, :, -overlap*self.model.sample_rate:]\n",
        "            next_segment = self.model.generate_continuation(last_sec, model.sample_rate, descriptions=prompt, progress=True)\n",
        "            segment = torch.cat([segment[:, :, :-overlap*self.model.sample_rate], next_segment], 2)\n",
        "            total_duration -= segment_duration - overlap\n",
        "            if total_duration < segment_duration:\n",
        "                segment_duration = total_duration + overlap\n",
        "                self.model.set_generation_params(\n",
        "                    use_sampling=True,\n",
        "                    top_k=250,\n",
        "                    duration=segment_duration\n",
        "                )\n",
        "\n",
        "        output = segment.detach().cpu().float()[0]\n",
        "        with NamedTemporaryFile(\"wb\", suffix=\".wav\", delete=False) as file:\n",
        "            file_path = f\"{file.name}\"\n",
        "            audio_write(\n",
        "                file.name, output, self.model.sample_rate, strategy=\"loudness\",\n",
        "                loudness_headroom_db=16, loudness_compressor=True, add_suffix=False)\n",
        "\n",
        "        output_file = File(path=file_path, allow_out_of_context_creation=True)\n",
        "        return output_file"
      ],
      "metadata": {
        "id": "lwMd0TZBPBl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " @entity\n",
        "# class MusicgenModel:\n",
        "#     def __init__(self):\n",
        "#         ...\n",
        "\n",
        "#     @pipe(on_startup=True, run_once=True)\n",
        "#     def load(self):\n",
        "#         import torchaudio\n",
        "#         from audiocraft.models import MusicGen\n",
        "\n",
        "#         self.model = MusicGen.get_pretrained(\"facebook/musicgen-melody\")\n",
        "\n",
        "     @pipe\n",
        "#     def predict(self, prompt: str, duration: int, samples: int, melodySample: File) -> File:\n",
        "#         from audiocraft.data.audio import audio_write\n",
        "\n",
        "#         self.model.set_generation_params(duration=duration)\n",
        "#         wav = self.model.generate_unconditional(samples)\n",
        "#         descriptions = prompt\n",
        "#         wav = self.model.generate(descriptions)\n",
        "\n",
        "#         melody, sr = torchaudio.load(str(melodySample.path), format=\"wav\")\n",
        "#         wav = self.model.generate_with_chroma(descriptions, melody[None].expand(duration, -1, -1), sr)\n",
        "\n",
        "#         for idx, one_wav in enumerate(wav):\n",
        "#             file_path = f\"/tmp/{idx}\"\n",
        "#             # Will save under {idx}.wav, with loudness normalization at -14 db LUFS.\n",
        "#             audio_write(\n",
        "#                 file_path,\n",
        "#                 one_wav.cpu(),\n",
        "#                 self.model.sample_rate,\n",
        "#                 strategy=\"loudness\",\n",
        "#                 loudness_compressor=True,\n",
        "#             )\n",
        "\n",
        "#         output_file = File(path=file_path + \".wav\", allow_out_of_context_creation=True)\n",
        "#         return output_file"
      ],
      "metadata": {
        "id": "MMZuksVRAxAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Pipeline() as builder:\n",
        "    prompt = Variable(\n",
        "        str,\n",
        "        title=\"Prompt\",\n",
        "        description='Describe the music to be generated, \\\n",
        "        e.g. \"rock song with a long guitar solo\"',\n",
        "    )\n",
        "    melodySample = Variable(\n",
        "        File,\n",
        "        title= \"Melody Sample\",\n",
        "        description = \"The audio melody that will be passed to model, \\\n",
        "        file must in wav format.\"\n",
        "    )\n",
        "    duration = Variable(\n",
        "        int,\n",
        "        title=\"Duration\",\n",
        "        description=\"Length of the music in seconds, \\\n",
        "        generation can take long so keep numbers low\",\n",
        "    )\n",
        "    samples = Variable(\n",
        "        int,\n",
        "        title=\"Samples number\",\n",
        "        description=\"Length of the music in seconds, \\\n",
        "        generation can take long so keep numbers low\",\n",
        "    )\n",
        "\n",
        "    model = MusicgenModel()\n",
        "\n",
        "    model.load()\n",
        "\n",
        "    output = model.predict(prompt, duration, samples, melodySample)\n",
        "\n",
        "    builder.output(output)\n",
        "\n",
        "    my_pl = builder.get_pipeline()\n",
        "    environments.create_environment(\n",
        "        \"Ainzoil/musicgen\",\n",
        "        python_requirements=[\n",
        "            \"torch==2.0.1\",\n",
        "            \"git+https://github.com/facebookresearch/audiocraft#egg=audiocraft\",\n",
        "            \"torchaudio==2.0.2\"\n",
        "        ],\n",
        "    )\n"
      ],
      "metadata": {
        "id": "WWLRHEMTBu1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remote_pipeline = pipelines.upload_pipeline(\n",
        "    my_pl,\n",
        "    \"Ainzoil/musicgen_large\",\n",
        "    environment_id_or_name=\"Ainzoil/musicgen\",\n",
        "    required_gpu_vram_mb=30_000,\n",
        "    accelerators=[\n",
        "        compute_requirements.Accelerator.nvidia_a100,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "VZcR87ANEFn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ry0uKtJpRcKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = my_pl.run(\n",
        "    \"mj, cinematic close up photo of an ethereal neural network organism, divine woman, anatomical face, biomechanical details\",\n",
        "    File(path=\"CantinaBand60.wav\"),\n",
        "    45,\n",
        "    1\n",
        "  )\n",
        "\n",
        "display_audio(output, 32000)"
      ],
      "metadata": {
        "id": "Ljw9r_84Jt6f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}