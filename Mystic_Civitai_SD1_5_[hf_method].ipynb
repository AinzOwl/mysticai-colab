{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AinzOwl/mysticai-colab/blob/main/Mystic_Civitai_SD1_5_%5Bhf_method%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mystic.Ai SD 1.5 civitai model deployment script**\n",
        "\n",
        "Hello, I'm [Ainzoal](https://ainz.sbs) you can find me on mystic.ai discord server, I'm back again with a new colab, this one is for deploying models from civitai to mistic.ai for an api inference, it is by no means the best way to do it but it works so yeah.\n",
        "\n",
        "the way this one work is by converting the model to diffusers then upload it to huggingface after that import it to mystic from huggingface like we did in 1.5 colab *(I told you its not best way)*\n",
        "\n",
        "Well enjoy and for any question or help yk where to find me.\n",
        "\n",
        "For SDXL [click here](https://github.com/AinzOwl/mysticai-colab/blob/main/mystic_ai_sdxl.ipynb)\n",
        "\n",
        "For normal V1.5 [click here](https://github.com/AinzOwl/mysticai-colab/blob/main/mystic_ai_sd1_5.ipynb)\n",
        "\n",
        "Notebooks Repo: [click here](https://github.com/AinzOwl/mysticai-colab)"
      ],
      "metadata": {
        "id": "0iT2IMfSQ3os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Packages\n",
        "!pip install pipeline-ai torch xformers\n",
        "!pip install -q transformers==4.31.0\n",
        "!pip install -q accelerate==0.21.0\n",
        "!pip install -q diffusers==0.20.0\n",
        "!pip install -q huggingface_hub==0.16.4\n",
        "!pip install -q omegaconf==2.3.0"
      ],
      "metadata": {
        "id": "VQT4mHrhHUkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download Model**\n",
        "\n",
        "First thing we need to download the model from civitai to do that right click the blue download button in https://civitai.com/ for the model you want, copy link and paste it in this one then click **enter**\n",
        "\n",
        "it will also ask you for extension it can be safetensors or like ckpt depending on your model, just type it there for example if model is a safetensor type `safetensors` and no **.** is needed"
      ],
      "metadata": {
        "id": "lgZCbib-R3Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title model download\n",
        "path = input(\"model path please: \")\n",
        "modelext = input(\"model extension pls: \")\n",
        "!curl -Lo model.{modelext} {path}\n",
        "# this next line will download the converter, dw its from huggingface themselves\n",
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/v0.20.0/scripts/convert_original_stable_diffusion_to_diffusers.py"
      ],
      "metadata": {
        "id": "5qj14kTMFmoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Convert**\n",
        "\n",
        "Thie cell is the one responsible for converting normal model into a diffusers ready one, just run it and wait a bit."
      ],
      "metadata": {
        "id": "htYN82zCSxLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_original_stable_diffusion_to_diffusers.py --checkpoint_path model.{modelext} --dump_path model/ --from_safetensors"
      ],
      "metadata": {
        "id": "K7aUrgHMFvDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Upload to huggingface**\n",
        "\n",
        "Those next cells will upload to huggingface, first you need tu supply your api key must be write since it will upload you can get it from [Here](https://huggingface.co/settings/tokens)\n",
        "\n",
        "Next you will have to create a new public model manually from [Here](https://huggingface.co/new), its best if you name it the same name of the civitai model so other people can use it, but its all up to you.\n",
        "\n",
        "Next run the second cell it will ask you for the id of the model you just created u can get it from the model page by clicking the copy icon"
      ],
      "metadata": {
        "id": "0aeyYXz8TL2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title model download\n",
        "hfapikey = input(\"model path please: \")\n",
        "!huggingface-cli login --token {hfapikey}"
      ],
      "metadata": {
        "id": "bnfWODSxNjI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Upload**\n",
        "\n",
        "Note before running this one make sure you have created a new model in huggingface using this [link](https://huggingface.co/new)"
      ],
      "metadata": {
        "id": "F7KYZXhHUE00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "modelName = input(\"Enter huggingface model id: \")\n",
        "api.upload_folder(\n",
        "    folder_path=\"model\",\n",
        "    repo_id=modelName,\n",
        "    repo_type=\"model\",\n",
        ")"
      ],
      "metadata": {
        "id": "bH8rpeDxNsUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mystic**\n",
        "\n",
        "Now we upload it to mystic.ai this is almost same as sd1.5 notebook so i'll be copy pasting most of notes ðŸ˜‚\n",
        "\n",
        "# **setup api key**\n",
        "\n",
        "When you run this it will ask you for your api key if you don't know where to find it it's [Here](https://mystic.ai/api-tokens) just type it and hit enter"
      ],
      "metadata": {
        "id": "tAH6o2XgUacc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Mystic.Ai Api Key\n",
        "\n",
        "api_key = input('Enter mystic.ai api key: ')\n",
        "!pipeline cluster login catalyst-api {api_key} -u https://www.mystic.ai -a"
      ],
      "metadata": {
        "id": "JAKfDltzMQAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import packages**\n",
        "Yeah just run this one and that's it, nothing to change"
      ],
      "metadata": {
        "id": "PPglEet-UufC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import packages\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
        "\n",
        "from pipeline import Pipeline, Variable, entity, pipe\n",
        "from pipeline.cloud import compute_requirements, environments, pipelines\n",
        "from pipeline.objects import Directory, File\n",
        "from pipeline.objects.graph import InputField, InputSchema"
      ],
      "metadata": {
        "id": "c3Cb8qTsMT-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **inputs**\n",
        "\n",
        "this is the configuration for the model inputs, you don't really need to change anything here unless you want to restrict some stuff or change some default values\n",
        "\n",
        "to change default values it's easy just search for name of value you want to change and change its default, for example you want to set default height to 1024 then go to height and change 512 with 1024\n",
        "\n",
        "```There's a bug that makes empty default inputs required, I just figured out you can bypass it by putting a space in default so yeah thats why there's a space for negative prompt if you are wondering```"
      ],
      "metadata": {
        "id": "jXbg1zD6Uxik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup inputs\n",
        "\n",
        "class ModelKwargs(InputSchema):\n",
        "    height: int | None = InputField(\n",
        "        title=\"Height\",\n",
        "        default=512,\n",
        "        ge=64,\n",
        "        le=1024,\n",
        "        multiple_of=8,\n",
        "    )\n",
        "\n",
        "    width: int | None = InputField(\n",
        "        title=\"Width\",\n",
        "        default=512,\n",
        "        ge=64,\n",
        "        le=1024,\n",
        "        multiple_of=8,\n",
        "    )\n",
        "\n",
        "    num_inference_steps: int | None = InputField(\n",
        "        title=\"Number of inference steps\",\n",
        "        default=25,\n",
        "    )\n",
        "\n",
        "    num_images_per_prompt: int | None = InputField(\n",
        "        default=1, title=\"Number of images\", ge=1, le=4\n",
        "    )\n",
        "\n",
        "    negative_prompt: str  | None = InputField(\n",
        "        default=' ',\n",
        "        title=\"Negative Prompt\",\n",
        "    )\n",
        "\n",
        "    guidance_scale: float | None = InputField(\n",
        "        default=7.5,\n",
        "        title=\"Guidance scale\",\n",
        "        ge=0.0,\n",
        "        le=20.0,\n",
        "        # multiple_of=0.1,\n",
        "    )\n",
        "\n",
        "    allow_nsfw: bool | None = InputField(\n",
        "        default=True,\n",
        "        title=\"Allow NSFW\",\n",
        "    )"
      ],
      "metadata": {
        "id": "hKAuIrF8MWnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting up the model**\n",
        "\n",
        "This one require a small input from you, just open it and change model_path with your model id from hugggingface (the one we just made, also if you go check it you'll find a bunch of files there ^^), to easily find it in code look for ``ainz/hineseLandscapeArt``\n",
        "\n"
      ],
      "metadata": {
        "id": "G780lu7YVEIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Model\n",
        "@entity\n",
        "class StableDiffusionModel:\n",
        "    def __init__(self):\n",
        "        ...\n",
        "\n",
        "    @pipe(on_startup=True, run_once=True)\n",
        "    def load(self):\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model_path = \"ainz/hineseLandscapeArt\"\n",
        "        self.pipe = StableDiffusionPipeline.from_pretrained(\n",
        "            model_path,\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "        self.pipe = self.pipe.to(device)\n",
        "\n",
        "        def disabled_safety_checker(images, clip_input):\n",
        "            if len(images.shape) == 4:\n",
        "                num_images = images.shape[0]\n",
        "                return images, [False] * num_images\n",
        "            else:\n",
        "                return images, False\n",
        "\n",
        "        self.no_filter = disabled_safety_checker\n",
        "        self.nsfw_filter = self.pipe.safety_checker\n",
        "\n",
        "    @pipe\n",
        "    def predict(self, prompt: str, kwargs: ModelKwargs) -> List[File]:\n",
        "        defaults = kwargs.to_dict()\n",
        "        del defaults[\"allow_nsfw\"]\n",
        "\n",
        "        if kwargs.allow_nsfw:\n",
        "            self.pipe.safety_checker = self.no_filter\n",
        "\n",
        "        images = self.pipe(prompt, **defaults).images\n",
        "\n",
        "        output_images = []\n",
        "        for i, image in enumerate(images):\n",
        "            path = Path(f\"/tmp/sd/image-{i}.jpg\")\n",
        "            path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            image.save(str(path))\n",
        "            output_images.append(File(path=path, allow_out_of_context_creation=True))\n",
        "\n",
        "        return output_images"
      ],
      "metadata": {
        "id": "kwEBaGvNMboT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Environment**\n",
        "\n",
        "Env is the one holding the packages that your model uses, the ones selected are the ones needed to get this diffusers model to run and same env can be used for different models so you kinda really just need to run this one ones and you're good"
      ],
      "metadata": {
        "id": "JMaKdiDiVkBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title setup mystic environment\n",
        "\n",
        "with Pipeline() as builder:\n",
        "    prompt = Variable(\n",
        "        str,\n",
        "        title=\"Prompt\"\n",
        "    )\n",
        "    kwargs = Variable(\n",
        "        ModelKwargs,\n",
        "        title=\"Model kwargs\",\n",
        "    )\n",
        "\n",
        "    model = StableDiffusionModel()\n",
        "\n",
        "    model.load()\n",
        "\n",
        "    output = model.predict(prompt, kwargs)\n",
        "\n",
        "    builder.output(output)\n",
        "\n",
        "my_pl = builder.get_pipeline()\n",
        "try:\n",
        "    environments.create_environment(\n",
        "        \"stable_diffusion_1_5\",\n",
        "        python_requirements=[\n",
        "            \"torch==2.0.1\",\n",
        "            \"transformers==4.30.2\",\n",
        "            \"diffusers==0.19.3\",\n",
        "            \"accelerate==0.21.0\",\n",
        "            \"xformers==0.0.21\",\n",
        "        ],\n",
        "    )\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "6kqbCb0mNCQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pushing the model**\n",
        "\n",
        "pushing is easy you just replace `hineseLandscapeArt` with what you named the model and thats it, if you used a different name for environement you can change it.\n",
        "\n",
        "For vram it depends on model how much it need but dont overkill it just try to find the balance.\n",
        "\n",
        "For accelerators check this page [Mystic Ai Docs](https://docs.mystic.ai/docs/gpus-and-accelerators) you'll find the id of each and pick one you want depending on price and vram"
      ],
      "metadata": {
        "id": "0fzPQthyVnOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Push the model (open this to change required gpu type)\n",
        "remote_pipeline = pipelines.upload_pipeline(\n",
        "    my_pl,\n",
        "    \"hineseLandscapeArt:latest\",\n",
        "    environment_id_or_name=\"stable_diffusion_1_5_civit\",\n",
        "    required_gpu_vram_mb=20_000,\n",
        "    accelerators=[\n",
        "        compute_requirements.Accelerator.nvidia_a100,\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(remote_pipeline.id)"
      ],
      "metadata": {
        "id": "TDgY2O-hNIl5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}