{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AinzOwl/mysticai-colab/blob/main/mystic_ai_sd1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mystic.Ai SD 1.5 model deployment script**\n",
        "\n",
        "Hello, I'm [Ainzoal](https://ainz.sbs) you can find me on mystic.ai discord server, I made this colab after suffering a lot to deploy my first model on v2 to point i quited but now v3 is out and with help of **Paul** i managed to deploy my first model, so i decided to give back and help other people who want to deploy on this super amazing platform.\n",
        "\n",
        "this colab is really easy, and if you face any errors just ask, anyway i tried to document it and make it as clear as possible so here you go.\n",
        "\n",
        "For SDXL [click here](https://github.com/AinzOwl/mysticai-colab/blob/main/mystic_ai_sdxl.ipynb)"
      ],
      "metadata": {
        "id": "cpqjO9ROTX8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **downloading packages**\n",
        "\n",
        "This was actually the error i faced i had missing packages, but worry not this will fix it just hit the download, also you dont need gpu for this so if it's enabled at top right u can just disable it to save on google resources."
      ],
      "metadata": {
        "id": "DfIFg2T2T-QU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsiyZqm8VRA8"
      },
      "outputs": [],
      "source": [
        "#@title Download Packages\n",
        "\n",
        "!pip install pipeline-ai torch transformers diffusers accelerate xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **setup api key**\n",
        "\n",
        "When you run this it will ask you for your api key if you don't know where to find it it's [Here](https://mystic.ai/api-tokens) just type it and hit enter"
      ],
      "metadata": {
        "id": "r2tYSntKTJ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Mystic.Ai Api Key\n",
        "\n",
        "api_key = input('Enter mystic.ai api key: ')\n",
        "!pipeline cluster login catalyst-api {api_key} -u https://www.mystic.ai -a"
      ],
      "metadata": {
        "id": "DpQuAJNUWAPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import packages**\n",
        "Yeah just run this one and that's it, nothing to change"
      ],
      "metadata": {
        "id": "06Ci5zHFTC-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import packages\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
        "\n",
        "from pipeline import Pipeline, Variable, entity, pipe\n",
        "from pipeline.cloud import compute_requirements, environments, pipelines\n",
        "from pipeline.objects import File\n",
        "from pipeline.objects.graph import InputField, InputSchema"
      ],
      "metadata": {
        "id": "UDZmFbvvViID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **inputs**\n",
        "\n",
        "this is the configuration for the model inputs, you don't really need to change anything here unless you want to restrict some stuff or change some default values\n",
        "\n",
        "to change default values it's easy just search for name of value you want to change and change its default, for example you want to set default height to 1024 then go to height and change 512 with 1024"
      ],
      "metadata": {
        "id": "hC0g81WtStzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup inputs\n",
        "\n",
        "class ModelKwargs(InputSchema):\n",
        "    height: int | None = InputField(\n",
        "        title=\"Height\",\n",
        "        default=512,\n",
        "        ge=64,\n",
        "        le=1024,\n",
        "        multiple_of=8,\n",
        "    )\n",
        "\n",
        "    width: int | None = InputField(\n",
        "        title=\"Width\",\n",
        "        default=512,\n",
        "        ge=64,\n",
        "        le=1024,\n",
        "        multiple_of=8,\n",
        "    )\n",
        "\n",
        "    num_inference_steps: int | None = InputField(\n",
        "        title=\"Number of inference steps\",\n",
        "        default=25,\n",
        "    )\n",
        "\n",
        "    num_images_per_prompt: int | None = InputField(\n",
        "        default=1, title=\"Number of images\", ge=1, le=4\n",
        "    )\n",
        "\n",
        "    negative_prompt: str  | None = InputField(\n",
        "        default='',\n",
        "        title=\"Negative Prompt\",\n",
        "    )\n",
        "\n",
        "    guidance_scale: float | None = InputField(\n",
        "        default=7.5,\n",
        "        title=\"Guidance scale\",\n",
        "        ge=0.0,\n",
        "        le=20.0,\n",
        "        # multiple_of=0.1,\n",
        "    )\n",
        "\n",
        "    allow_nsfw: bool | None = InputField(\n",
        "        default=True,\n",
        "        title=\"Allow NSFW\",\n",
        "    )"
      ],
      "metadata": {
        "id": "nHOBAiOcVogI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting up the model**\n",
        "\n",
        "here you select your model and vae\n",
        "\n",
        "for model just open the code of the block and replace prompthero/openjourney-v4 with your model id from huggingface.co\n",
        "\n",
        "if you want to use a vae you can uncomment the `vae_model` and `vae=` by removing the `#` before them, please note some vae models on huggingface dont have config.json which will lead to an error.\n"
      ],
      "metadata": {
        "id": "t26G3JyASSX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Model(open and replace the model id search for prompthero/openjourney-v4) to use a vae uncomment vae and replace \"cumprod/yozora-vae\" in vae model\n",
        "\n",
        "@entity\n",
        "class StableDiffusionModel:\n",
        "    def __init__(self):\n",
        "        ...\n",
        "\n",
        "    @pipe(on_startup=True, run_once=True)\n",
        "    def load(self):\n",
        "        #vae_model = AutoencoderKL.from_pretrained(\"cumprod/yozora-vae\")\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model_id = \"prompthero/openjourney-v4\"\n",
        "\n",
        "        self.pipe = StableDiffusionPipeline.from_pretrained(\n",
        "            model_id,\n",
        "            use_safetensors=True,\n",
        "            #vae= vae_model,\n",
        "        )\n",
        "        self.pipe = self.pipe.to(device)\n",
        "\n",
        "        def disabled_safety_checker(images, clip_input):\n",
        "            if len(images.shape) == 4:\n",
        "                num_images = images.shape[0]\n",
        "                return images, [False] * num_images\n",
        "            else:\n",
        "                return images, False\n",
        "\n",
        "        self.no_filter = disabled_safety_checker\n",
        "        self.nsfw_filter = self.pipe.safety_checker\n",
        "\n",
        "    @pipe\n",
        "    def predict(self, prompt: str, kwargs: ModelKwargs) -> List[File]:\n",
        "        defaults = kwargs.to_dict()\n",
        "        del defaults[\"allow_nsfw\"]\n",
        "\n",
        "        if kwargs.allow_nsfw:\n",
        "            self.pipe.safety_checker = self.no_filter\n",
        "\n",
        "        images = self.pipe(prompt, **defaults).images\n",
        "\n",
        "        output_images = []\n",
        "        for i, image in enumerate(images):\n",
        "            path = Path(f\"/tmp/sd/image-{i}.jpg\")\n",
        "            path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            image.save(str(path))\n",
        "            output_images.append(File(path=path, allow_out_of_context_creation=True))\n",
        "\n",
        "        return output_images"
      ],
      "metadata": {
        "id": "0EeLD-KIVthd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Environment**\n",
        "\n",
        "Env is the one holding the packages that your model uses, the ones selected are the ones needed to get this diffusers model to run and same env can be used for different models so you kinda really just need to run this one ones and you're good"
      ],
      "metadata": {
        "id": "-cYUI7SRR_Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title setup mystic environment\n",
        "\n",
        "with Pipeline() as builder:\n",
        "    prompt = Variable(\n",
        "        str,\n",
        "        title=\"Prompt\"\n",
        "    )\n",
        "    kwargs = Variable(\n",
        "        ModelKwargs,\n",
        "        title=\"Model kwargs\",\n",
        "    )\n",
        "\n",
        "    model = StableDiffusionModel()\n",
        "\n",
        "    model.load()\n",
        "\n",
        "    output = model.predict(prompt, kwargs)\n",
        "\n",
        "    builder.output(output)\n",
        "\n",
        "my_pl = builder.get_pipeline()\n",
        "try:\n",
        "    environments.create_environment(\n",
        "        \"stable_diffusion_1_5\",\n",
        "        python_requirements=[\n",
        "            \"torch==2.0.1\",\n",
        "            \"transformers==4.30.2\",\n",
        "            \"diffusers==0.19.3\",\n",
        "            \"accelerate==0.21.0\",\n",
        "            \"xformers==0.0.21\",\n",
        "        ],\n",
        "    )\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "T19bl4g3Vy-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pushing the model**\n",
        "\n",
        "pushing is easy you just replace `openjourney-v4` with what you named the model and thats it, if you used a different name for environement you can change it.\n",
        "\n",
        "For vram it depends on model how much it need but dont overkill it just try to find the balance.\n",
        "\n",
        "For accelerators check this page [Mystic Ai Docs](https://docs.mystic.ai/docs/gpus-and-accelerators) you'll find the id of each and pick one you want depending on price and vram"
      ],
      "metadata": {
        "id": "SqYcI5BGRgFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Push the model (open this to change required gpu type)\n",
        "remote_pipeline = pipelines.upload_pipeline(\n",
        "    my_pl,\n",
        "    \"openjourney-v4:latest\",\n",
        "    environment_id_or_name=\"stable_diffusion_1_5\",\n",
        "    required_gpu_vram_mb=20_000,\n",
        "    accelerators=[\n",
        "        compute_requirements.Accelerator.nvidia_a100,\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(remote_pipeline.id)"
      ],
      "metadata": {
        "id": "7Z5F50UzN2l4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}